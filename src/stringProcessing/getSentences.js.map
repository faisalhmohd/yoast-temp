{"version":3,"sources":["../../../src/stringProcessing/getSentences.js"],"names":["text","blocks","block","split","newLineRegex","sentences","getSentencesFromBlockCached","newLines","RegExp","getSentencesFromBlock","sentenceTokenizer","createTokenizer","tokenizer","tokens","tokenize","length","getSentencesFromTokens"],"mappings":";;;;;;kBAwCe,UAAUA,IAAV,EAAiB;AAC/BA,QAAO,4CAAiBA,IAAjB,CAAP;AACA,KAAIC,SAAS,qBAAWD,IAAX,CAAb;;AAEA;AACAC,UAAS,uBAASA,MAAT,EAAiB,UAAUC,KAAV,EAAkB;AAC3C,SAAOA,MAAMC,KAAN,CAAaC,YAAb,CAAP;AACA,EAFQ,CAAT;;AAIA,KAAMC,YAAY,uBAASJ,MAAT,EAAiBK,2BAAjB,CAAlB;;AAEA,QAAO,sBAAQD,SAAR,EAAmB,wCAAnB,CAAP;AACA,C;;AAnDD;;AAOA;;AACA;;AACA;;;;;;AAEA;AAZA;AAaA,IAAME,WAAW,YAAjB;;AAEA;;;AARA;AASA,IAAMH,eAAe,IAAII,MAAJ,CAAYD,QAAZ,CAArB;;AAEA;;;;;;AAMA,SAASE,qBAAT,CAAgCP,KAAhC,EAAwC;AACvC,KAAMQ,oBAAoB,iCAA1B;;AADuC,6BAETA,kBAAkBC,eAAlB,EAFS;AAAA,KAE/BC,SAF+B,yBAE/BA,SAF+B;AAAA,KAEpBC,MAFoB,yBAEpBA,MAFoB;;AAGvCH,mBAAkBI,QAAlB,CAA4BF,SAA5B,EAAuCV,KAAvC;;AAEA,QAAOW,OAAOE,MAAP,KAAkB,CAAlB,GAAsB,EAAtB,GAA2BL,kBAAkBM,sBAAlB,CAA0CH,MAA1C,CAAlC;AACA;;AAED,IAAMP,8BAA8B,uBAASG,qBAAT,CAApC;;AAEA","file":"getSentences.js","sourcesContent":["// Lodash imports.\nimport { filter } from \"lodash-es\";\nimport { flatMap } from \"lodash-es\";\nimport { isEmpty } from \"lodash-es\";\nimport { negate } from \"lodash-es\";\nimport { memoize } from \"lodash-es\";\n\n// Internal dependencies.\nimport { getBlocks } from \"../helpers/html.js\";\nimport { unifyNonBreakingSpace as unifyWhitespace } from \"../stringProcessing/unifyWhitespace.js\";\nimport SentenceTokenizer from \"./SentenceTokenizer\";\n\n// Character classes.\nconst newLines = \"\\n\\r|\\n|\\r\";\n\n// Regular expressions.\nconst newLineRegex = new RegExp( newLines );\n\n/**\n * Returns the sentences from a certain block.\n *\n * @param {string} block The HTML inside a HTML block.\n * @returns {Array<string>} The list of sentences in the block.\n */\nfunction getSentencesFromBlock( block ) {\n\tconst sentenceTokenizer = new SentenceTokenizer();\n\tconst { tokenizer, tokens } = sentenceTokenizer.createTokenizer();\n\tsentenceTokenizer.tokenize( tokenizer, block );\n\n\treturn tokens.length === 0 ? [] : sentenceTokenizer.getSentencesFromTokens( tokens );\n}\n\nconst getSentencesFromBlockCached = memoize( getSentencesFromBlock );\n\n/**\n * Returns sentences in a string.\n *\n * @param {String} text The string to count sentences in.\n * @returns {Array} Sentences found in the text.\n */\nexport default function( text ) {\n\ttext = unifyWhitespace( text );\n\tlet blocks = getBlocks( text );\n\n\t// Split each block on newlines.\n\tblocks = flatMap( blocks, function( block ) {\n\t\treturn block.split( newLineRegex );\n\t} );\n\n\tconst sentences = flatMap( blocks, getSentencesFromBlockCached );\n\n\treturn filter( sentences, negate( isEmpty ) );\n}\n"]}